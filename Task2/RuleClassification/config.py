from ray import tune

train_config = {
    "lr": 0.05,
    "momentum": 0,
    "nesterov": False,
    "weight_decay": 0.0,
    "name": "test_translit",
    "translit": True,
    "test": True,
    "train_path": "/data/jingwen/sanskrit/wsmp_train.json",
    "eval_path": "/data/jingwen/sanskrit/corrected_wsmp_dev.json",
    "test_path": "/data/jingwen/sanskrit/test_set",
    "batch_size": 64,
    "epochs": 10,
    "embedding_size": 64,
    "encoder_hidden_size": 256,
    "encoder_max_ngram": 6,
    "encoder_char2token_mode": "max",
    "classifier_hidden_dim": 256,
    "classifer_num_layers": 2,
    "dropout": 0.0,
    "tag_rules": True,
    "stemming_rule_cutoff": 5,
    "cuda": True,
    "out_folder": "../sanskrit",
    "submission_dir": "result_submission",
    "checkpoint_dir": "./checkpoint",
}


tune_config = config = {
    "lr": 0.05,
    # "batch_size": tune.choice([16, 32, 64, 128]),
    "batch_size": 64,
    "epochs": tune.choice([1, 2]),
    "momentum": 0,
    "nesterov": False,
    "weight_decay": 0,
    "embedding_size": 32,
    "encoder_hidden_size": 256,
    "encoder_max_ngram": 6,
    "encoder_char2token_mode": "max",
    "classifier_hidden_dim": 256,
    "classifer_num_layers": 2,
    "dropout": 0.0,
    "tag_rules": True,
    "stemming_rule_cutoff": 5,
    "name": "test_translit",
    "translit": True,
    "test": True,
    "train_path": "/data/jingwen/sanskrit/wsmp_train.json",
    "eval_path": "/data/jingwen/sanskrit/corrected_wsmp_dev.json",
    "test_path": "/data/jingwen/sanskrit/test_set",
    "cuda": True,
    "out_folder": "../sanskrit",
    "submission_dir": "result_submission",
    "checkpoint_dir": "./checkpoint",
}
